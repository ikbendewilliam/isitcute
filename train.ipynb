{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bit2276ef816aa547ce9381ebb5bb439dbf",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import glob\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50(input_shape=(224, 224, 3), include_top=True, weights=\"imagenet\", input_tensor=None, pooling='max', classes=1000,)\n",
    "base_output = base_model.output\n",
    "final_output = Dense(2, activation='softmax')(base_output)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(dataset):\n",
    "    dataset_path = pathlib.Path('data', dataset)\n",
    "\n",
    "    datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input,\n",
    "                                 rotation_range=40,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 zoom_range=0.2,\n",
    "                                 horizontal_flip=True)\n",
    "                                 \n",
    "    return datagen.flow_from_directory(str(dataset_path),\n",
    "                                       target_size=(224, 224),\n",
    "                                       batch_size=32,\n",
    "                                       shuffle=True,\n",
    "                                       class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 10143 images belonging to 2 classes.\n",
      "Found 1509 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 687s 2s/step - loss: 0.6897 - accuracy: 0.5855 - val_loss: 0.6855 - val_accuracy: 0.6230\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 688s 2s/step - loss: 0.6841 - accuracy: 0.6093 - val_loss: 0.6818 - val_accuracy: 0.5898\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 671s 2s/step - loss: 0.6790 - accuracy: 0.6203 - val_loss: 0.6755 - val_accuracy: 0.6289\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 675s 2s/step - loss: 0.6761 - accuracy: 0.6144 - val_loss: 0.6750 - val_accuracy: 0.5918\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 667s 2s/step - loss: 0.6731 - accuracy: 0.6105 - val_loss: 0.6731 - val_accuracy: 0.6113\n"
     ]
    }
   ],
   "source": [
    "train_generator = make_generator('train')\n",
    "validation_generator = make_generator('test')\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=final_output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_generator,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=300,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=16)\n",
    "\n",
    "model.save('iscute.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 660s 2s/step - loss: 0.6704 - accuracy: 0.6163 - val_loss: 0.6703 - val_accuracy: 0.6074\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 676s 2s/step - loss: 0.6695 - accuracy: 0.6111 - val_loss: 0.6778 - val_accuracy: 0.5781\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 676s 2s/step - loss: 0.6681 - accuracy: 0.6062 - val_loss: 0.6570 - val_accuracy: 0.6562\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 679s 2s/step - loss: 0.6657 - accuracy: 0.6123 - val_loss: 0.6776 - val_accuracy: 0.5566\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 776s 3s/step - loss: 0.6631 - accuracy: 0.6165 - val_loss: 0.6632 - val_accuracy: 0.6152\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 944s 3s/step - loss: 0.6632 - accuracy: 0.6137 - val_loss: 0.6614 - val_accuracy: 0.6035\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 935s 3s/step - loss: 0.6620 - accuracy: 0.6112 - val_loss: 0.6469 - val_accuracy: 0.6602\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 937s 3s/step - loss: 0.6620 - accuracy: 0.6129 - val_loss: 0.6651 - val_accuracy: 0.6074\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 945s 3s/step - loss: 0.6613 - accuracy: 0.6159 - val_loss: 0.6711 - val_accuracy: 0.6016\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 44107s 147s/step - loss: 0.6611 - accuracy: 0.6104 - val_loss: 0.6479 - val_accuracy: 0.6348\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=300,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=16)\n",
    "\n",
    "model.save('iscute2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_loaded, filename):\n",
    "    img = image.load_img(filename, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    return model_loaded.predict (images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "not cute, cute\n",
      "data/predict\\000ada55d36b4bcb.jpg: [[0.1550897  0.84491026]]\n",
      "data/predict\\00a300e8b0cef4d3.jpg: [[0.16990297 0.8300971 ]]\n",
      "correct\n",
      "data/predict\\00a3654c1cf00d11.jpg: [[0.6231487  0.37685138]]\n",
      "data/predict\\00a36f96e31731c4.jpg: [[0.16352025 0.8364798 ]]\n",
      "data/predict\\00a42a80e5e8d194.jpg: [[0.207901 0.792099]]\n",
      "data/predict\\00a7655d4eabf186.jpg: [[0.19447638 0.80552363]]\n",
      "data/predict\\00abfe9035972732.jpg: [[0.23517293 0.7648271 ]]\n",
      "data/predict\\00ac70478d4727bf.jpg: [[0.11416932 0.88583064]]\n",
      "correct\n",
      "data/predict\\00acf53b127218c2.jpg: [[0.6291745 0.3708256]]\n",
      "correct\n",
      "data/predict\\01IrQfV.jpg: [[0.3009802 0.6990198]]\n",
      "data/predict\\01KyAvz.jpg: [[0.67832774 0.3216722 ]]\n",
      "correct\n",
      "data/predict\\01ZSRgh.jpg: [[0.24337521 0.75662476]]\n",
      "correct\n",
      "data/predict\\0thB4ca.jpg: [[0.20880605 0.7911939 ]]\n",
      "correct\n",
      "data/predict\\0TizTVN.jpg: [[0.30732447 0.69267553]]\n",
      "correct\n",
      "data/predict\\0tOXueK.jpg: [[0.41438872 0.5856112 ]]\n",
      "correct\n",
      "data/predict\\0TskMIN.jpg: [[0.23276414 0.7672359 ]]\n",
      "correct\n",
      "data/predict\\0udCiHx.jpg: [[0.40410912 0.59589094]]\n",
      "correct\n",
      "data/predict\\0UHSdfR.jpg: [[0.2752222 0.7247778]]\n",
      "correct\n",
      "data/predict\\0uhYm1R.jpg: [[0.24321897 0.7567811 ]]\n",
      "correct\n",
      "data/predict\\0vnm9YP.jpg: [[0.15232709 0.8476729 ]]\n",
      "correct\n",
      "data/predict\\0vo7tgm.jpg: [[0.2800253 0.7199747]]\n",
      "correct\n",
      "data/predict\\0vtozcK.jpg: [[0.23508571 0.76491433]]\n",
      "correct\n",
      "data/predict\\0vTyJgU.jpg: [[0.20653594 0.7934641 ]]\n",
      "correct\n",
      "data/predict\\0VxIKIl.jpg: [[0.12698244 0.8730176 ]]\n",
      "correct\n",
      "data/predict\\0VzNwOj.jpg: [[0.3086568  0.69134325]]\n",
      "correct\n",
      "data/predict\\0W4l8c9.jpg: [[0.24305771 0.7569422 ]]\n",
      "correct\n",
      "data/predict\\0wUbr21.jpg: [[0.26657388 0.7334261 ]]\n",
      "correct\n",
      "data/predict\\0wz8jsI.jpg: [[0.20571019 0.79428977]]\n",
      "correct\n",
      "data/predict\\0WzVO5n.jpg: [[0.2892909  0.71070915]]\n",
      "correct\n",
      "data/predict\\0xv2U3V.jpg: [[0.41704336 0.5829566 ]]\n",
      "correct\n",
      "data/predict\\0y4QiSC.jpg: [[0.2546477 0.7453523]]\n",
      "data/predict\\0YAe6Qx.jpg: [[0.5210606 0.4789394]]\n",
      "correct\n",
      "data/predict\\0YkhkYR.jpg: [[0.4994776  0.50052243]]\n",
      "correct\n",
      "data/predict\\0YL53mj.jpg: [[0.49546385 0.50453615]]\n",
      "correct\n",
      "data/predict\\0YpzRjL.jpg: [[0.14990644 0.8500935 ]]\n",
      "correct\n",
      "data/predict\\0z15oHd.jpg: [[0.15589269 0.8441073 ]]\n",
      "correct\n",
      "data/predict\\0zcgOHq.jpg: [[0.41579717 0.5842029 ]]\n",
      "correct\n",
      "data/predict\\1AAw2sI.jpg: [[0.21882512 0.78117496]]\n",
      "correct\n",
      "data/predict\\1AZ5pLq.jpg: [[0.4503308  0.54966927]]\n",
      "correct\n",
      "data/predict\\1azQjo3.jpg: [[0.39843377 0.6015662 ]]\n",
      "data/predict\\SPOILER_cute_spiderbart.png: [[0.351217 0.648783]]\n",
      "not cute, cute\n",
      "correct: 31 (0.775%)\n",
      "FP: 7, FN: 2\n"
     ]
    }
   ],
   "source": [
    "model_loaded = load_model('iscute2.h5')\n",
    "model_loaded.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "correct = 0\n",
    "falsePositives = 0\n",
    "falseNegatives = 0\n",
    "total = 0\n",
    "print('not cute, cute')\n",
    "for filename in glob.glob('data/predict/*'):\n",
    "    classes = predict(model_loaded, filename)\n",
    "    if (len(filename) == 33):\n",
    "        total += 1\n",
    "        if (classes[0][0] > classes[0][1]):\n",
    "            correct += 1\n",
    "            print('correct')\n",
    "        else:\n",
    "            falsePositives += 1\n",
    "    elif(len(filename) == 24):\n",
    "        total += 1\n",
    "        if (classes[0][0] < classes[0][1]):\n",
    "            correct += 1\n",
    "            print('correct')\n",
    "        else:\n",
    "            falseNegatives += 1\n",
    "    print(filename + ': ' + str(classes))\n",
    "\n",
    "print('not cute, cute')\n",
    "print('correct: ' + str(correct) + ' (' + str(correct / total) + '%)')\n",
    "print('FP: ' + str(falsePositives) + ', FN: ' + str(falseNegatives))"
   ]
  }
 ]
}